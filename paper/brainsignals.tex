\documentclass[12pt,twoside]{article}
\usepackage{jmlda}

\newcommand{\bff}{\mathbf{f}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bTheta}{\boldsymbol{\Theta}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bbb}{\mathbf{b}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\Sim}{\myop{Sim}}
\newcommand{\Rel}{\myop{Rel}}
\newcommand{\var}{\textrm{var}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\xfeat}{\mathbf{\chi}}
\newcommand{\yfeat}{y}

%\NOREVIEWERNOTES
\title
    {Прогнозирование намерений по cигналам ECoG}
\author
    {Калиниченко~О.\,И., Ремизова~А.\,С.} % основной список авторов, выводимый в оглавление
\thanks
{	Научный руководитель:  Стрижов~В.\,В. 
	Задачу поставил:  Стрижов~В.\,В.
	Консультант:  Исаченко~Р.\,В.}
% \email{author@site.ru}
\organization
{$^1$ Московский физико-технический институт}
\abstract
{Работа посвящена построению системы тестирования $L \times K$ прогностических моделей для различных критериев качества.
	Рассматривается случай коррелированных входных и выходных сигналов электрокортикограммы и фазовых траекторий движения конечностей высокой размерности.
	Рассматривается задача предсказания намерений по сигналам головного мозга.
	Входные данные -- сигналы электрокортикограммы (ECoG).
	Для выявления и устранения скрытых зависимостей используются методы снижения размерности пространства и отбора признаков.
	Предложенная система тестирования оценивает качество прогноза моделей и ошибку.
	Вычислительный эксперимент проводится на данных ECoG проекта NeuroTycho.
	
	\bigskip
	\textbf{Ключевые слова}: \emph {декодирование временных рядов, PLS, QPFS, электрокортикограмма, траекторий движения конечностей}.}

\begin{document}
\maketitle

\section{Введение}
Работа посвящена исследованию методов моделирования нейросетевого интерфейса (BCI) \cite{Motrenko17ECoG}.
Входные данные -- сигналы мозга, полученные с помощью электрокортикографии (ECoG) и электроэнцефалографии (EEG). ECoG-сигналы имеют более высокое разрешение и большую амплитуду, однако для их получения требуется непосредственное подсоединение электродов к коре головного мозга. Одной из задач при построении систем BCI является предсказание намерений.

Предлагается декодировать исходные сигналы и спрогнозировать траекторию движения верхних конечностей. Исходное пространство имеет избыточно высокую размерность. Линейная зависимость между признаками приводит к мультиколлинеарности. Для устранения мультиколлинеарности предлагается применить методы понижения размерности и отбора признаков.

Признаковое описание многомерного временного ряда существует в пространствах независимых и зависимых переменных. Для учета существующих закономерностей в исходном и выходном пространстве используется скрытое пространство латентных переменных.  В скрытом пространстве происходит согласование между образами исходных пространств.

В эксперименте рассматриваются следующие модели: метод частных наименьших квадратов (PLS) \cite{Isachenko17PLS}, отбор признаков с помощью квадратичного программирования (QPFS) \cite{Katrutsa17QPFS}, метод Белсли (Belsley) и вариации этих методов.
% Нелинейные модели -- нейросети.

PLS является методом отбора признаков

Описание метода QPFS...

Предлагается система тестирования прогностических моделей с оценкой качества и анализом ошибки. Подобный инструмент может применяться не только в задаче анализа сигналов мозга, но и во многих других задачах, связанных с прогнозированием многомерных временных рядов.

\section{Постановка задачи}
\paragraph{Постановка задачи предсказания}

Задана выборка $\mathfrak{D}= \left( \bX, \bY \right)$, где $\bX \in \RR^{m \times n}$ --- матрица объектов, $\bX = \left[ \xfeat_1 \dots \xfeat_n \right]$, где $\xfeat_j \in \mathbb{R}^{m}$ --- вектор значений $j$-го признака на элементах выборки; $\bY \in \RR^{m \times r}$ --- матрица ответов, $\bY = \left[ \yfeat_1 \dots \yfeat_r \right]$. Имеется линейная модель $\bff$ с набором параметров $\btheta$ из пространства $\RR^{n \times r}$, предсказывающая
$\by \in \RR^r$ по $\bx \in \RR^n$, следующего вида:
\begin{equation}
\bff(\bx, \btheta) = \underset{1 \times n}{\bx}\T \underset{n \times r}{\btheta}.
\label{eq::linear_model}
\end{equation}


Задана функция ошибки $S$ на выборке $\mathfrak{D}$  и модели $\bff$ с параметрами $\btheta$.
 Задачей является поиск наилучших параметров $\btheta^*$, то есть таких, при которых функция ошибки минимальна:
\begin{equation}
\btheta^* = \argmin_{\btheta \in \Theta} S(\btheta| \mathfrak{D}, \bff).
\label{eq::error_function}
\end{equation}

В случае кореллированных данных $\bX$ решение задачи выбора оптимального вектора параметров $\btheta$ нестабильно.  


За $\bF(\bX, \btheta)$ обозначена матрица $\left[\bff(\bx_1, \btheta), \bff(\bx_2, \btheta), \dots, \bff(\bx_m, \btheta)\right]\T$. Рассматривается квадратичная функция ошибки:
\begin{equation}
	{\bigl\| \bF(\bX, \btheta) - \bY \bigr\| }_2^2 
	\rightarrow \min_{\btheta \in \RR^{n \times r}} 
	\label{eq::error_linear}
\end{equation}
Если пространство признаков имеет высокую размерность, вероятно, что матрица $\bX$ близка к вырожденной, а потому решение проблемы оптимизации \eqref{eq::error_linear} будет нестабильным. Для решения указанной задачи применяются методы отбора признаков.



\paragraph{Постановка задачи отбора признаков}

Пусть $\cJ = \{ 1, \dots, n \}$ --- множество индексов признаков, а $\cA \subseteq \cJ$ --- его некоторое подмножество. Тогда линейную модель $\bff$ на подмножестве признаков $\cA$ можно определить как:

\begin{equation}
	\bff (\bx, \cA, \btheta) = \underset{1 \times |\cA|}{\bx_{\cA}} \underset{|\cA| \times r}{\btheta} \label{eq:fs_model}
\end{equation}

 Функция ошибки $S$ теперь вычисляется на выборке $\mathfrak{D}$, модели $\bff$ с параметрами $\btheta$ и на $\cA$.

Тогда задача предсказания определяется как поиск набора признаков $\cA$ и матрицы параметров $\btheta^* \in \RR^{|\cA| \times r}$ такого, что:
\begin{equation}
\btheta^* = \arg \min_{\btheta  \in \RR^{|\cA| \times r}}   S(\theta, \cA | \mathfrak{D}, \bff)	\label{eq::fs_forecast}
\end{equation}


Задача отбора признаков поставлена как:
\begin{equation}
	\cA^* = \argmin_{\cA \in cJ} Q(\cA | \bX, \by), \label{eq::fs_problem}
\end{equation}

где $Q : \cA \to \RR$ --- это некоторый критерий качества,который определяет качество выбранного подмножества признаков $\cA \subseteq \cJ$.

Для решения этой задачи не обязательно требуется оценка оптимального вектора параметров $\btheta^*$. Она использует зависимости между векторами $\xfeat_j, j \in \cJ$ и целевыми векторами $y_i, i \in \{1, \dots, r \}$.

\paragraph{PLS.}
Метод частных наименьших квадратов PLS рассматривает в качестве признаков линейные комбинации исходных. Предполагается, что существует скрытое пространство латентных переменных малой размерности $l$ ($l < n, r$). Происходит поиск матрицы $\bT \in \RR^{m \times l}$, которая наилучшим образом описывает матрицы $\bX$ и $\bY$. 

\begin{align}
	\underset{m \times n}{\bX} &= \underset{m \times l}{\bT\T} \cdot
	\underset{l \times n}{\bP\T} + \underset{m \times n}{\bE}
	\label{eq::PLS_X} \\
	\underset{m \times r}{\bY} &= \underset{m \times l}{\bU\T} \cdot
	% \underset{l \times l}{\textrm{diag}(\bbeta)}\cdot
	\underset{l \times r}{\bQ\T} + \underset{m \times r}{\bF}
	\label{eq::PLS_Y}
\end{align}




$\bT$ ---

\paragraph{QPFS} 

Чтобы вычислить матрицу $\bQ$ и вектор $\bbb$

\begin{align}
\Sim & \label{eq::Sim} \\
\Rel & \label{eq::Rel}
\end{align}

Коэффициент корреляции Пирсона определяется как:

$$\rho_{ij} =\frac{
\cov(\bx_i, \bx_j)
}{
\sqrt{\var(\bx_i) \cdot \var(\bx_j)}
} $$


\paragraph{Метрики}

Пусть имеются истинный прогноз $\bY = (\by_1, \by_2, \dots, \by_m)$ и предсказание $\mathbf{\hat{Y}} = (\mathbf{\hat{y}}_1, \mathbf{\hat{y}}_2, \dots, \mathbf{\hat{y}}_m)$; $\by_i$ и $\mathbf{\hat{y}}_i$, $i = 1, 2, \dots, m$ -- вектора размерности $r$.

Среднеквадратичная  ошибка (mean squared error):

\begin{equation}
	\text{MSE}(\bY, \mathbf{\hat{Y}}) =
	\frac{1}{m}
	\sum^m_{i=1}
	{\bigl\| \mathbf{y}_i - \mathbf{\hat{y}}_i \bigr\| }_2^2 
	\label{eq::error_mse}
\end{equation}

Корень среднеквадратичной ошибки (root-mean-squared error):

\begin{equation}
\text{RMSE}(\bY, \mathbf{\hat{Y}}) =
\sqrt{\text{MSE}(\bY, \mathbf{\hat{Y}})}
\label{eq::error_rmse}
\end{equation}

Нормированная среднеквадратичная ошибка (scaled mean squared error):

\begin{equation}
\text{sMSE}(\bY, \mathbf{\hat{Y}}) =
\frac{
\sum^m_{i=1}
{\bigl\| \mathbf{y}_i - \mathbf{\hat{y}}_i \bigr\| }_2^2 
}{
\sum^m_{i=1}
{\bigl\| \mathbf{y}_i - \mathbf{\overline{y}} \bigr\| }_2^2 
}, \;
\mathbf{\overline{y}} = \frac{1}{m} \sum_{i=1}^{m} y_i
\label{eq::error_smse}
\end{equation}


MAE, MADE, Коэффициент корреляции. Различные параметры модели из \cite{Katrutsa17QPFS}.

Сложность модели


\begin{thebibliography}{1}
\bibitem{bci}
    \BibAuthor{
    	J. del R.\; Mill?n,
    	F. \; Renken,
    	J. \; Mouri?o and
    	W. \; Gerstner}
    \BibTitle{Brain-actuated interaction}~//
    \BibJournal{Artif. Intell.}, 159(2004) 241–259.
\bibitem{Isachenko17PLS}
    \BibAuthor{
    	Isachenko \; R.,
    	Vladimirova \; M.,
    	Strijov \; V.}
    \BibTitle{Dimensionality reduction for time series decoding and
    	forecasting problems}~//
    \BibJournal{Machine Learning and Data Analysis}.
\bibitem{Katrutsa15StressTest}
	\BibAuthor{
	Katrutsa \; A.,
	Strijov \; V.}
	\BibTitle{Stress test procedure for feature selection algorithms}, 2015~//
\BibJournal{Expert System with Applications}, 142, 172–183
\bibitem{Katrutsa17QPFS}
    \BibAuthor{
    	Katrutsa \; A.,
    	Strijov \; V.}
    \BibTitle{Comprehensive study of feature selection methods to solve
    	multicollinearity problem according to evaluation criteria}, 2017~//
    \BibJournal{Expert System with Applications}, 76, 1-11.
\bibitem{Motrenko17ECoG}
	\BibAuthor{
		Motrenko \; A.,
		Strijov \; V.}
	\BibTitle{Multi-way Feature Selection for ECoG-based Brain-Computer
	Interface}~//
	\BibJournal{???}.

\end{thebibliography}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}
